{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61b1d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Bayesian Neural Network for EUI Estimation (with Uncertainty)\n",
    "# \n",
    "# This notebook loads pre-cleaned Seattle building data and sets up the input matrix\n",
    "# for Bayesian neural network modeling with PyMC. We include feature preprocessing and a data split.\n",
    "\n",
    "# ## Environment setup (run once in terminal)\n",
    "# python3 -m venv bpd_env\n",
    "# source bpd_env/bin/activate\n",
    "# pip install pandas scikit-learn pymc arviz matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1d5a6b",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# ## 1. Load libraries and dataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Path to cleaned data\n",
    "file_path = \"/Users/georgepaul/Desktop/Research-Project/seattle/seattle-data-cleaned.csv\"\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(file_path)\n",
    "print(\"Data shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daea3171",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# ## 2. Define relevant features\n",
    "\n",
    "target = \"SiteEUI(kBtu/sf)\"\n",
    "\n",
    "numerical_features = [\n",
    "    \"YearBuilt\", \"NumberofFloors\", \"NumberofBuildings\",\n",
    "    \"PropertyGFATotal\", \"ENERGYSTARScore\",\n",
    "    \"Electricity(kWh)\", \"NaturalGas(kBtu)\",\n",
    "    \"SteamUse(kBtu)\", \"GHGEmissionsIntensity\"\n",
    "]\n",
    "\n",
    "# Automatically detect one-hot encoded categorical features\n",
    "categorical_features = [col for col in df.columns if col.startswith(\"EPAPropertyType_\") or col.startswith(\"LargestPropertyUseType_\")]\n",
    "\n",
    "all_features = numerical_features + categorical_features\n",
    "\n",
    "X = df[all_features]\n",
    "y = df[target]\n",
    "\n",
    "print(\"Feature matrix shape:\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2392ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 3. Scale numeric features\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = X.copy()\n",
    "X_scaled[numerical_features] = scaler.fit_transform(X[numerical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe1bf38",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# ## 4. Train-test split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Training size:\", X_train.shape)\n",
    "print(\"Test size:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600b8b01",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# ## Ready for BNN Modeling with PyMC\n",
    "\n",
    "# This is the end of the data preparation stage.\n",
    "# In the next notebook/file, we will define and train a BNN using PyMC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f5280c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "notebook_metadata_filter": "jupytext_format_version"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
