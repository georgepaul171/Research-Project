{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e49359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Bayesian Neural Network for Seattle Dataset\n",
    "# This notebook uses imputed and pre-split energy data to train a Bayesian Neural Network using PyMC and JAX."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ce6f0f",
   "metadata": {},
   "source": [
    "### 1. Imports & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98721bff",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import pymc as pm\n",
    "import pytensor.tensor as pt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import arviz as az\n",
    "import pymc.sampling.jax\n",
    "import os\n",
    "import numpyro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63afa768",
   "metadata": {},
   "source": [
    "### 2. Load Imputed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce71b7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"/Users/georgepaul/Desktop/Research-Project/seattle/data/X_train_imputed.csv\")\n",
    "y_train = pd.read_csv(\"/Users/georgepaul/Desktop/Research-Project/seattle/data/y_train_imputed.csv\")\n",
    "X_test = pd.read_csv(\"/Users/georgepaul/Desktop/Research-Project/seattle/data/X_test_imputed.csv\")\n",
    "y_test = pd.read_csv(\"/Users/georgepaul/Desktop/Research-Project/seattle/data/y_test_imputed.csv\")\n",
    "\n",
    "# Rename columns if needed\n",
    "if y_train.columns[0] != \"SiteEUI(kBtu/sf)\":\n",
    "    y_train.columns = [\"SiteEUI(kBtu/sf)\"]\n",
    "if y_test.columns[0] != \"SiteEUI(kBtu/sf)\":\n",
    "    y_test.columns = [\"SiteEUI(kBtu/sf)\"]\n",
    "\n",
    "y_train = y_train.squeeze()\n",
    "y_test = y_test.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee0a1e8",
   "metadata": {},
   "source": [
    "### 3. Standardize Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dec677a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train).astype(np.float32)\n",
    "X_test_scaled = scaler.transform(X_test).astype(np.float32)\n",
    "\n",
    "y_train_np = y_train.values.astype(np.float32)\n",
    "y_test_np = y_test.values.astype(np.float32)\n",
    "\n",
    "n_features = X_train.shape[1]\n",
    "trace_file = \"bnn_trace_seattle.nc\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f7b527",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### 4. Build or Load BNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a96b92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if os.path.exists(trace_file):\n",
    "    print(f\"Loading existing trace from {trace_file}...\")\n",
    "    trace = az.from_netcdf(trace_file)\n",
    "    with pm.Model() as bnn_model:\n",
    "        X_data = pm.Data(\"X_data\", X_train_scaled)\n",
    "        y_data = pm.Data(\"y_data\", y_train_np)\n",
    "\n",
    "        w1 = pm.Normal(\"w1\", mu=0, sigma=1, shape=(n_features, 32))\n",
    "        b1 = pm.Normal(\"b1\", mu=0, sigma=1, shape=(32,))\n",
    "        z1 = pt.tanh(pt.dot(X_data, w1) + b1)\n",
    "\n",
    "        w2 = pm.Normal(\"w2\", mu=0, sigma=1, shape=(32, 16))\n",
    "        b2 = pm.Normal(\"b2\", mu=0, sigma=1, shape=(16,))\n",
    "        z2 = pt.tanh(pt.dot(z1, w2) + b2)\n",
    "\n",
    "        w_out = pm.Normal(\"w_out\", mu=0, sigma=1, shape=(16,))\n",
    "        b_out = pm.Normal(\"b_out\", mu=0, sigma=1)\n",
    "        mu = pt.dot(z2, w_out) + b_out\n",
    "\n",
    "        sigma = pm.HalfNormal(\"sigma\", sigma=1)\n",
    "        y_obs = pm.Normal(\"y_obs\", mu=mu, sigma=sigma, observed=y_train_np)\n",
    "else:\n",
    "    with pm.Model() as bnn_model:\n",
    "        X_data = pm.Data(\"X_data\", X_train_scaled)\n",
    "        y_data = pm.Data(\"y_data\", y_train_np)\n",
    "\n",
    "        w1 = pm.Normal(\"w1\", mu=0, sigma=1, shape=(n_features, 32))\n",
    "        b1 = pm.Normal(\"b1\", mu=0, sigma=1, shape=(32,))\n",
    "        z1 = pt.tanh(pt.dot(X_data, w1) + b1)\n",
    "\n",
    "        w2 = pm.Normal(\"w2\", mu=0, sigma=1, shape=(32, 16))\n",
    "        b2 = pm.Normal(\"b2\", mu=0, sigma=1, shape=(16,))\n",
    "        z2 = pt.tanh(pt.dot(z1, w2) + b2)\n",
    "\n",
    "        w_out = pm.Normal(\"w_out\", mu=0, sigma=1, shape=(16,))\n",
    "        b_out = pm.Normal(\"b_out\", mu=0, sigma=1)\n",
    "        mu = pt.dot(z2, w_out) + b_out\n",
    "\n",
    "        sigma = pm.HalfNormal(\"sigma\", sigma=1)\n",
    "        y_obs = pm.Normal(\"y_obs\", mu=mu, sigma=sigma, observed=y_train_np)\n",
    "\n",
    "        trace = pm.sampling.jax.sample_numpyro_nuts(\n",
    "            draws=500,\n",
    "            tune=500,\n",
    "            target_accept=0.9,\n",
    "            chains=1,\n",
    "            random_seed=42\n",
    "        )\n",
    "        trace = az.from_dict(trace)\n",
    "        trace.to_netcdf(trace_file)\n",
    "        print(f\"Trace saved to {trace_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6f7d92",
   "metadata": {},
   "source": [
    "### 5. Posterior Predictive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb497b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with bnn_model:\n",
    "    pm.set_data({\"X_data\": X_test_scaled})\n",
    "    ppc = pm.sample_posterior_predictive(trace, var_names=[\"y_obs\"], random_seed=42)\n",
    "\n",
    "mu_pred_eval = ppc[\"y_obs\"]\n",
    "pred_mean = mu_pred_eval.mean(axis=0)\n",
    "pred_std = mu_pred_eval.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb3ab40",
   "metadata": {},
   "source": [
    "### 6. Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5be5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_test_np, pred_mean)\n",
    "rmse = mean_squared_error(y_test_np, pred_mean, squared=False)\n",
    "mae = mean_absolute_error(y_test_np, pred_mean)\n",
    "\n",
    "print(\"========= Evaluation Metrics =========\")\n",
    "print(f\"R² Score                  : {r2:.3f}\")\n",
    "print(f\"RMSE                      : {rmse:.2f}\")\n",
    "print(f\"MAE                       : {mae:.2f}\")\n",
    "print(f\"Avg Std Dev (Uncertainty) : {np.mean(pred_std):.2f}\")\n",
    "print(f\"Max Std Dev               : {np.max(pred_std):.2f}\")\n",
    "\n",
    "# Save to file\n",
    "with open(\"bnn_seattle_metrics.txt\", \"w\") as f:\n",
    "    f.write(\"========= Evaluation Metrics =========\\n\")\n",
    "    f.write(f\"R² Score                  : {r2:.3f}\\n\")\n",
    "    f.write(f\"RMSE                      : {rmse:.2f}\\n\")\n",
    "    f.write(f\"MAE                       : {mae:.2f}\\n\")\n",
    "    f.write(f\"Avg Std Dev (Uncertainty) : {np.mean(pred_std):.2f}\\n\")\n",
    "    f.write(f\"Max Std Dev               : {np.max(pred_std):.2f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d280851",
   "metadata": {},
   "source": [
    "### 7. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14475788",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "axes[0, 0].errorbar(range(len(pred_mean)), pred_mean, yerr=pred_std, fmt='o', alpha=0.5, label=\"Predicted ± std\")\n",
    "axes[0, 0].plot(range(len(y_test_np)), y_test_np, 'k.', alpha=0.6, label=\"Actual\")\n",
    "axes[0, 0].set_title(\"Predicted vs Actual\")\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True)\n",
    "\n",
    "axes[0, 1].hist(pred_mean, bins=30, alpha=0.7, label=\"Predicted\")\n",
    "axes[0, 1].hist(y_test_np, bins=30, alpha=0.7, label=\"Actual\")\n",
    "axes[0, 1].set_title(\"Distribution of Predictions vs Actual\")\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True)\n",
    "\n",
    "axes[1, 0].scatter(pred_mean, pred_std, alpha=0.5)\n",
    "axes[1, 0].set_title(\"Uncertainty vs Prediction\")\n",
    "axes[1, 0].grid(True)\n",
    "\n",
    "residuals = y_test_np - pred_mean\n",
    "axes[1, 1].scatter(pred_mean, residuals, alpha=0.5)\n",
    "axes[1, 1].axhline(y=0, color='r', linestyle='--')\n",
    "axes[1, 1].set_title(\"Residual Plot\")\n",
    "axes[1, 1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"bnn_seattle_results.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8291897f",
   "metadata": {},
   "source": [
    "### 8. Trace Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a51cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = az.summary(trace)\n",
    "summary_df.to_csv(\"bnn_trace_summary.csv\")\n",
    "summary_df"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "notebook_metadata_filter": "jupytext_format_version"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
