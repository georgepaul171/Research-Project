digraph {
	graph [size="16.95,16.95"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	6037481952 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	5995757232 [label=AddmmBackward0]
	5689154128 -> 5995757232
	5689154128 [label=AddBackward0]
	5995754976 -> 5689154128
	5995927248 [label="layers.2.bias_mu
 (1)" fillcolor=lightblue]
	5995927248 -> 5995754976
	5995754976 [label=AccumulateGrad]
	5968179648 -> 5689154128
	5968179648 [label=MulBackward0]
	6018271312 -> 5968179648
	6018271312 [label=Log1PBackward0]
	5995745760 -> 6018271312
	5995745760 [label=ExpBackward0]
	5968181664 -> 5995745760
	5995937728 [label="layers.2.bias_rho
 (1)" fillcolor=lightblue]
	5995937728 -> 5968181664
	5968181664 [label=AccumulateGrad]
	6018284464 -> 5995757232
	6018284464 [label=ReluBackward0]
	5696076000 -> 6018284464
	5696076000 [label=AddmmBackward0]
	5968172928 -> 5696076000
	5968172928 [label=AddBackward0]
	5968177584 -> 5968172928
	5995921808 [label="layers.1.bias_mu
 (32)" fillcolor=lightblue]
	5995921808 -> 5968177584
	5968177584 [label=AccumulateGrad]
	5968174992 -> 5968172928
	5968174992 [label=MulBackward0]
	5995271344 -> 5968174992
	5995271344 [label=Log1PBackward0]
	5995266592 -> 5995271344
	5995266592 [label=ExpBackward0]
	5967960224 -> 5995266592
	5995930688 [label="layers.1.bias_rho
 (32)" fillcolor=lightblue]
	5995930688 -> 5967960224
	5967960224 [label=AccumulateGrad]
	5968174080 -> 5696076000
	5968174080 [label=ReluBackward0]
	5995271776 -> 5968174080
	5995271776 [label=AddmmBackward0]
	6018274288 -> 5995271776
	6018274288 [label=AddBackward0]
	5967958448 -> 6018274288
	5995378352 [label="layers.0.bias_mu
 (64)" fillcolor=lightblue]
	5995378352 -> 5967958448
	5967958448 [label=AccumulateGrad]
	5967957008 -> 6018274288
	5967957008 [label=MulBackward0]
	5967961232 -> 5967957008
	5967961232 [label=Log1PBackward0]
	5967959984 -> 5967961232
	5967959984 [label=ExpBackward0]
	5967959120 -> 5967959984
	5995934048 [label="layers.0.bias_rho
 (64)" fillcolor=lightblue]
	5995934048 -> 5967959120
	5967959120 [label=AccumulateGrad]
	5967964640 -> 5995271776
	5967964640 [label=TBackward0]
	5967966032 -> 5967964640
	5967966032 [label=AddBackward0]
	5967957968 -> 5967966032
	5583480512 [label="layers.0.weight_mu
 (64, 4)" fillcolor=lightblue]
	5583480512 -> 5967957968
	5967957968 [label=AccumulateGrad]
	5967957824 -> 5967966032
	5967957824 [label=MulBackward0]
	5967957872 -> 5967957824
	5967957872 [label=Log1PBackward0]
	5967955472 -> 5967957872
	5967955472 [label=ExpBackward0]
	5967967280 -> 5967955472
	5542908688 [label="layers.0.weight_rho
 (64, 4)" fillcolor=lightblue]
	5542908688 -> 5967967280
	5967967280 [label=AccumulateGrad]
	5968171728 -> 5696076000
	5968171728 [label=TBackward0]
	5696245232 -> 5968171728
	5696245232 [label=AddBackward0]
	5967956576 -> 5696245232
	5995934208 [label="layers.1.weight_mu
 (32, 64)" fillcolor=lightblue]
	5995934208 -> 5967956576
	5967956576 [label=AccumulateGrad]
	5967957248 -> 5696245232
	5967957248 [label=MulBackward0]
	5967961568 -> 5967957248
	5967961568 [label=Log1PBackward0]
	5967966224 -> 5967961568
	5967966224 [label=ExpBackward0]
	4451854624 -> 5967966224
	5995937488 [label="layers.1.weight_rho
 (32, 64)" fillcolor=lightblue]
	5995937488 -> 4451854624
	4451854624 [label=AccumulateGrad]
	5995754784 -> 5995757232
	5995754784 [label=TBackward0]
	5968169520 -> 5995754784
	5968169520 [label=AddBackward0]
	5967967568 -> 5968169520
	5995929168 [label="layers.2.weight_mu
 (1, 32)" fillcolor=lightblue]
	5995929168 -> 5967967568
	5967967568 [label=AccumulateGrad]
	5967965168 -> 5968169520
	5967965168 [label=MulBackward0]
	4451854192 -> 5967965168
	4451854192 [label=Log1PBackward0]
	6018094592 -> 4451854192
	6018094592 [label=ExpBackward0]
	6018096656 -> 6018094592
	5995922128 [label="layers.2.weight_rho
 (1, 32)" fillcolor=lightblue]
	5995922128 -> 6018096656
	6018096656 [label=AccumulateGrad]
	5995757232 -> 6037481952
}
